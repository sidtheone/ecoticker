# EcoTicker — User Stories

**Date:** 2026-02-09
**Source:** Derived from 9-expert business panel analysis (`2026-02-09-business-panel-analysis.md`)
**Status:** Draft — for review

---

## How to Use This Document

Each user story follows the format:
> **As a** [persona], **I want** [goal], **so that** [benefit].

Stories are grouped by the recommendation they serve. Each includes acceptance criteria and a complexity tag (S/M/L). Review them one at a time — approve, modify, or reject each before implementation.

---

## Recommendation #1: Surface Sub-Scores and Categories in the UI

> Currently the LLM computes `healthScore`, `ecoScore`, `econScore` and stores them in `score_history`, but the UI only shows the aggregate `currentScore`.

### US-1.0: Research optimal sub-scoring approach with LLMs
**As a** developer, **I want** to research and document the best approach for generating reliable, consistent sub-scores (health, ecology, economy) from LLMs, **so that** the scoring system is well-designed before we build UI around it.

**Acceptance Criteria:**
- Research and compare approaches:
  - Single prompt returning all scores at once (current approach)
  - Chain-of-thought prompting: ask LLM to reason about each dimension before scoring
  - Multi-pass scoring: separate LLM calls per sub-score for independence
  - Rubric-based scoring: provide explicit criteria per score level per dimension
- Evaluate trade-offs: cost (API calls), latency, score consistency, explainability
- Document the recommended approach with rationale
- Include example prompts for the chosen approach
- Output: design doc in `docs/plans/` for review before implementation

**Complexity:** M (research task)

---

### US-1.1: View sub-score breakdown on topic detail page
**As a** topic researcher, **I want** to see health, ecology, and economy sub-scores on the topic detail page, **so that** I can understand which dimension is driving the overall severity score.

**Acceptance Criteria:**
- Topic detail page displays health, eco, and econ sub-scores alongside the main score
- Each sub-score uses the same color scale as the main score (green/yellow/orange/red)
- Sub-scores are fetched from the latest `score_history` entry for the topic
- Clear labels explain what each sub-score represents (e.g., "Health Impact", "Ecological Impact", "Economic Impact")
- Mobile-responsive layout

**Complexity:** M

---

### US-1.2: View sub-score history on topic detail page
**As a** topic researcher, **I want** to see historical trends for each sub-score (health, eco, econ) on the topic detail page, **so that** I can identify which dimension is escalating over time.

**Acceptance Criteria:**
- ScoreChart on the topic detail page shows optional sub-score trend lines
- User can toggle sub-scores on/off (default: off, to keep it clean)
- Sub-score data comes from existing `score_history` table (already stored)
- Legend labels explain what each sub-score represents

**Complexity:** M

---

### US-1.3: Filter dashboard by category
**As a** dashboard visitor, **I want** to filter topics by category (air_quality, climate, pollution, etc.), **so that** I can focus on the environmental domain I care about.

**Acceptance Criteria:**
- Filter bar or dropdown appears above TopicGrid
- Shows only categories that have at least one topic
- "All" option shows everything (default)
- Filter state persists during the session (not across refreshes)
- 10 valid categories: air_quality, deforestation, ocean, climate, pollution, biodiversity, wildlife, energy, waste, water

**Complexity:** S

---

### US-1.4: See category label on topic card
**As a** dashboard visitor, **I want** to see the category (e.g., "climate", "pollution") displayed on each topic card, **so that** I can quickly identify what domain a topic belongs to.

**Acceptance Criteria:**
- Category shown as a subtle tag/chip on the TopicCard
- Uses consistent styling with the urgency badge
- Does not clutter the card — secondary visual weight

**Complexity:** S

---

## Recommendation #2: Add Score Explainability

> The LLM prompt currently asks for a score but no reasoning. Users see "72" with no explanation of why.

### US-2.1: See why a topic has its current score
**As a** dashboard visitor, **I want** to see a brief explanation of why a topic received its current score, **so that** I can trust the scoring and understand the underlying factors.

**Acceptance Criteria:**
- Topic detail page shows a "Score Reasoning" section
- Reasoning is 2-3 sentences generated by the LLM during batch scoring
- Stored in a new `reasoning` field (in `score_history` or `topics` table)
- Batch pipeline LLM prompt is updated to request reasoning alongside the score
- Fallback: if no reasoning is available (legacy data), show "Reasoning not available for this period"

**Complexity:** M

---

### US-2.2: See which articles influenced the score
**As a** topic researcher, **I want** to see which specific articles contributed to a score change, **so that** I can verify the scoring against the source material.

**Acceptance Criteria:**
- Topic detail page links score history entries to the articles that were analyzed in that batch
- Articles are already stored with `topic_id` and `fetched_at` — correlation is possible by date
- Each score history entry shows a "Based on N articles" link that scrolls to or filters the article list

**Complexity:** M

---

### US-2.3: Understand what the score scale means
**As a** first-time visitor, **I want** to see an explanation of what scores 0-100 mean, **so that** I can interpret the numbers correctly.

**Acceptance Criteria:**
- An info icon or "What do scores mean?" link on the dashboard
- Opens a modal or inline explainer with the scale:
  - 0-29: Informational (green) — low environmental impact
  - 30-59: Moderate (yellow) — notable concern
  - 60-79: Critical (orange) — significant environmental impact
  - 80-100: Breaking (red) — severe, immediate impact
- Also explains sub-scores briefly (health, ecology, economy)

**Complexity:** S

---

## Recommendation #3: Replace Static Headline with Dynamic Insight

> Homepage shows "EcoTicker" / "Environmental news impact tracker" — describes the product, not what it tells you.

### US-3.1: See a dynamic insight headline on the dashboard
**As a** returning visitor, **I want** the dashboard headline to tell me what's happening right now (e.g., "3 topics escalated today"), **so that** I immediately know if something needs my attention.

**Acceptance Criteria:**
- Headline dynamically computed from current data:
  - "N topics escalated today" (if any topics increased score by >5)
  - "Environmental risk is trending up/down this week" (based on average score change)
  - "All topics stable" (if no significant changes)
- Falls back to "EcoTicker — Environmental news impact tracker" if no data available
- Updates when data refreshes

**Complexity:** S

---

## Recommendation #4: Make Keywords User-Configurable

> Topics are limited to 5 hardcoded keywords in `BATCH_KEYWORDS` env var.

### US-4.1: Add a new topic to track via the UI
**As a** power user, **I want** to add a custom topic/keyword to track, **so that** I can monitor environmental issues that matter to me personally.

**Acceptance Criteria:**
- Admin-authenticated UI or settings page to add new keywords
- New keywords are added to the batch pipeline's keyword list
- Next batch run picks up the new keyword and creates a topic
- Validation: keyword must be 2-100 characters, no special characters
- Requires API key authentication (existing auth system)

**Complexity:** M

---

### US-4.2: Remove a topic I no longer want to track
**As a** power user, **I want** to remove a topic from tracking, **so that** the dashboard stays focused on what matters.

**Acceptance Criteria:**
- Admin-authenticated action to deactivate a topic
- Topic is soft-deleted (hidden from dashboard, data preserved)
- Historical data remains in `score_history` for potential re-activation
- Requires API key authentication

**Complexity:** S

---

### US-4.3: See the list of tracked keywords
**As a** site administrator, **I want** to see all currently tracked keywords and their status, **so that** I can manage what the system monitors.

**Acceptance Criteria:**
- Settings or admin page listing all keywords
- Shows which keywords are active vs. inactive
- Shows last batch run date per keyword
- Protected by admin API key

**Complexity:** S

---

## Recommendation #5: Add One Backup News Source

> Single dependency on NewsAPI is a fragility risk.

### US-5.1: System continues working when NewsAPI is down
**As a** site operator, **I want** the batch pipeline to fall back to an alternative news source when NewsAPI is unavailable, **so that** scoring continues uninterrupted.

**Acceptance Criteria:**
- Batch pipeline attempts NewsAPI first
- On failure (timeout, 5xx, rate limit), falls back to a secondary source (RSS feeds or GDELT)
- Logs which source was used for each batch run
- Articles from all sources are deduplicated by URL

**Complexity:** M

---

### US-5.2: See which data source powered each article
**As a** topic researcher, **I want** to know which news source (NewsAPI, RSS, etc.) provided each article, **so that** I can assess source reliability.

**Acceptance Criteria:**
- Articles table includes a `source_type` field (e.g., "newsapi", "rss", "gdelt")
- Article list on topic detail page shows source type as a subtle indicator
- Does not break existing article display

**Complexity:** S

---

## Recommendation #6: Add Shareable Public Topic URLs + Embed Widget

> No mechanism for virality. The product is trapped inside the app.

### US-6.1: Share a topic's current status via a link
**As a** journalist, **I want** to share a link to a specific topic's status page, **so that** I can reference EcoTicker scores in my articles.

**Acceptance Criteria:**
- Topic detail pages (`/topic/[slug]`) are publicly accessible (already true)
- Add a "Share" button that copies the URL to clipboard
- URL includes the topic name in the page title (for social previews)
- Add Open Graph meta tags (title, description, image) for rich link previews

**Complexity:** S

---

### US-6.2: Embed a live topic sparkline on an external website
**As a** blogger or journalist, **I want** an embeddable widget showing a topic's live score and sparkline, **so that** I can display EcoTicker data on my own site.

**Acceptance Criteria:**
- New `/embed/[slug]` page renders a minimal sparkline + score (no navigation, no header)
- Embeddable via `<iframe>` with configurable width/height
- Auto-refreshes every 5 minutes
- "Copy embed code" button on the topic detail page
- Respects dark/light theme via query parameter (`?theme=dark`)

**Complexity:** M

---

### US-6.3: Generate a social card image for a topic
**As a** social media user, **I want** a visually appealing preview card when I share an EcoTicker link on Twitter/LinkedIn, **so that** the shared link attracts attention.

**Acceptance Criteria:**
- Dynamic OG image generated per topic (using Next.js OG image generation or similar)
- Shows: topic name, current score, sparkline, urgency badge
- Correct dimensions for Twitter (1200x628) and LinkedIn
- Updates when the score changes

**Complexity:** M

---

## Recommendation #7: Add Score Anomaly Detection

> Scores update blindly with no sanity checking. A model change could silently break all scores.

### US-7.1: Flag suspicious score jumps
**As a** site operator, **I want** the system to flag when a topic's score changes by more than 30 points in a single batch run, **so that** I can investigate whether it's a real event or a model anomaly.

**Acceptance Criteria:**
- After scoring, compare new score to previous score
- If delta > 30 (configurable threshold), log a warning with details
- Flagged anomalies visible in audit logs or a dedicated view
- Score still updates (don't block), but the flag enables human review

**Complexity:** S

---

### US-7.2: Store raw LLM responses for debugging
**As a** site operator, **I want** raw LLM responses stored alongside extracted scores, **so that** I can debug scoring issues and re-score historical data when models improve.

**Acceptance Criteria:**
- Batch pipeline stores the full LLM response text in a new field (`raw_response` in `score_history` or a separate table)
- Only stored for the most recent N batch runs (configurable, default 30) to manage storage
- Accessible via admin API endpoint

**Complexity:** S

---

## Recommendation #8: Add Basic Analytics

> Zero product metrics. No way to know if the product is useful.

### US-8.1: Track page views per topic
**As a** site operator, **I want** to know which topics are viewed most frequently, **so that** I can prioritize content coverage and understand user interests.

**Acceptance Criteria:**
- Lightweight page-view counter (no external analytics dependency)
- Stored per topic per day in a new `topic_views` table
- Viewable via admin API endpoint
- Privacy-respecting: no user identification, just counts

**Complexity:** S

---

### US-8.2: See a simple analytics dashboard
**As a** site operator, **I want** a basic analytics view showing top topics by views and overall traffic trends, **so that** I can understand product usage without external tools.

**Acceptance Criteria:**
- Admin-only page or API endpoint
- Shows: top 10 topics by views (last 7 days), total daily views trend
- Simple bar chart or table format
- Protected by admin API key

**Complexity:** M

---

## Recommendation #9: SQLite Daily Backup in Cron

> Single-file SQLite database with no backup mechanism.

### US-9.1: Automatic daily database backup
**As a** site operator, **I want** the database automatically backed up daily, **so that** I can recover from data corruption or accidental deletion.

**Acceptance Criteria:**
- Cron job runs SQLite `.backup` command daily (before or after batch run)
- Backups stored in a `/backups` directory with date-stamped filenames
- Retains last 7 backups, deletes older ones automatically
- Backup failure logged as an error (does not block batch run)

**Complexity:** S

---

## Recommendation #10: User Feedback Mechanism

> No feedback loop. Users can't report bad scores or contribute signal.

### US-10.1: Report an inaccurate score
**As a** dashboard visitor, **I want** to flag a score that seems wrong, **so that** the system can improve its accuracy over time.

**Acceptance Criteria:**
- "Report score" button on topic detail page
- Opens a simple form: "Too high / Too low / Other" + optional comment
- Submissions stored in a new `score_feedback` table
- No authentication required (to lower friction), but rate-limited
- Feedback viewable by admin via API

**Complexity:** S

---

### US-10.2: See aggregated feedback on score accuracy
**As a** site operator, **I want** to see which topics receive the most "inaccurate score" reports, **so that** I can identify calibration issues in the scoring model.

**Acceptance Criteria:**
- Admin API endpoint returning feedback counts per topic
- Sorted by most-reported topics
- Shows breakdown: too high vs. too low vs. other
- Time-filterable (last 7 days, 30 days, all time)

**Complexity:** S

---

## Summary

| Rec # | Stories | Total Complexity |
|---|---|---|
| 1. Sub-scores & categories | US-1.0, 1.1, 1.2, 1.3, 1.4 | M + M + M + S + S |
| 2. Score explainability | US-2.1, 2.2, 2.3 | M + M + S |
| 3. Dynamic headline | US-3.1 | S |
| 4. Configurable keywords | US-4.1, 4.2, 4.3 | M + S + S |
| 5. Backup news source | US-5.1, 5.2 | M + S |
| 6. Shareable/embeddable | US-6.1, 6.2, 6.3 | S + M + M |
| 7. Anomaly detection | US-7.1, 7.2 | S + S |
| 8. Basic analytics | US-8.1, 8.2 | S + M |
| 9. Database backup | US-9.1 | S |
| 10. User feedback | US-10.1, 10.2 | S + S |

**Total: 23 user stories** (13 Small, 10 Medium, 0 Large)

---

**Next step:** Review these one at a time. For each, decide: approve, modify, or reject. Then use `/sc:workflow` to plan implementation.
