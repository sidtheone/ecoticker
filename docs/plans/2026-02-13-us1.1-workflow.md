# US-1.1 Implementation Workflow â€” Multi-Dimensional Scoring Architecture

**Date:** 2026-02-13
**User Story:** US-1.1 â€” Implement the US-1.0 scoring architecture
**Branch:** `v2`
**Depends on:** Phase 0 (DONE â€” commit d25ebb0)
**Blocks:** US-1.2, US-1.3, US-2.1, US-2.2, US-3.1, US-6.3, US-10.1
**Estimated files changed:** ~8 files
**Estimated net change:** ~1,200 lines

---

## Why This Plan Is Structured the Way It Is

US-1.1 is a **full vertical slice** â€” it touches the scoring pipeline, the seed data, and tests. But critically, Phase 0 already did the hard part: the schema, types, and API routes are DONE. What remains is:

1. The **batch pipeline** â€” the engine that actually produces scores
2. The **seed script** â€” realistic demo data that exercises the new scoring
3. **Tests** â€” unit tests for the new scoring functions + updated integration tests

The plan is structured in 4 phases that can be implemented sequentially in a single session. Each phase has a clear checkpoint so you can verify before moving on.

---

## Pre-Implementation Audit: What's Already Done vs. What's Left

### âœ… Already Complete (Phase 0)

| Component | Status | Notes |
|-----------|--------|-------|
| `src/db/schema.ts` | âœ… Done | All 8 tables, all v2 columns including levels, reasoning, JSONB |
| `src/db/index.ts` | âœ… Done | Drizzle connection pool |
| `src/lib/types.ts` | âœ… Done | `SeverityLevel`, sub-scores on `Topic`, `ScoreHistoryEntry` |
| `GET /api/topics` | âœ… Done | Returns healthScore, ecoScore, econScore, scoreReasoning |
| `GET /api/topics/[slug]` | âœ… Done | Returns levels, reasoning, overallSummary, anomalyDetected in scoreHistory |
| `GET /api/ticker` | âœ… Done | Unchanged (lightweight payload) |
| `GET /api/movers` | âœ… Done | Unchanged |
| `tests/helpers/mock-db.ts` | âœ… Done | Chainable Drizzle mock infrastructure |
| Docker + CI | âœ… Done | postgres:17-alpine, GitHub Actions |

### ðŸ”´ Needs Implementation (This Workflow)

| Component | Status | Scope |
|-----------|--------|-------|
| `scripts/batch.ts` | ðŸ”´ Still SQLite + old prompt | Complete rewrite |
| `scripts/seed.ts` | ðŸ”´ Still SQLite + no reasoning | Complete rewrite |
| `src/lib/scoring.ts` | ðŸ”´ Doesn't exist | NEW: scoring utility functions |
| `tests/scoring.test.ts` | ðŸ”´ Doesn't exist | NEW: unit tests for scoring |
| `tests/batch.test.ts` | ðŸŸ¡ Partial | Update for new scoring functions |
| `tests/seed.test.ts` | ðŸŸ¡ Partial | Update for v2 seed data |

---

## Phase 1: Scoring Core Library (`src/lib/scoring.ts`)

**Goal:** Extract all scoring logic into a pure, testable module with zero side effects.

**Why a separate file?** The scoring functions (validateScore, computeOverallScore, deriveUrgency, detectAnomaly) are referenced by both the batch pipeline AND tests. Putting them in `scripts/batch.ts` would make them harder to import in tests (scripts aren't in the `@/` alias). A dedicated `src/lib/scoring.ts` makes them importable everywhere via `@/lib/scoring`.

### Files to create/modify:

#### 1.1 â€” Create `src/lib/scoring.ts` (NEW â€” ~120 lines)

**Contains:**

```typescript
// Constants
export const LEVEL_RANGES: Record<string, [number, number]>
// MINIMAL: [0, 25], MODERATE: [26, 50], SIGNIFICANT: [51, 75], SEVERE: [76, 100]

export const DIMENSION_WEIGHTS = {
  eco: 0.40,   // Ecological â€” core mission
  health: 0.35, // Health â€” most salient to users
  econ: 0.25,   // Economic â€” contextual
} as const;

// Functions (all from US-1.0 Part 4.4)
export function validateScore(level: string, score: number): ValidatedScore
export function computeOverallScore(health: number, eco: number, econ: number): number
export function deriveUrgency(overallScore: number): string
export function detectAnomaly(previousScore: number, newScore: number, topicName: string, dimension: string): boolean
export function scoreToLevel(score: number): SeverityLevel  // reverse mapping: score â†’ level
```

**Key design decisions:**

- `validateScore()`: Clamps score to level range. Returns `{ level, score, clamped }`. Handles INSUFFICIENT_DATA (-1). Falls back to MODERATE for unknown levels.
- `computeOverallScore()`: Excludes INSUFFICIENT_DATA dimensions (score === -1). Renormalizes weights. Falls back to 50 if all dimensions are insufficient.
- `deriveUrgency()`: Pure mapping: 80+ â†’ breaking, 60+ â†’ critical, 30+ â†’ moderate, else informational. Backward compatible with existing urgency system.
- `detectAnomaly()`: Returns boolean for >25pt jump. Logs warning. Called per-dimension.
- `scoreToLevel()`: Reverse of levelâ†’range. Useful for seed data and tests.

**Dependencies:** Only `src/lib/types.ts` (for `SeverityLevel` type).

### Checkpoint 1
```bash
npx jest tests/scoring.test.ts  # All scoring unit tests pass
```

---

## Phase 2: Batch Pipeline Rewrite (`scripts/batch.ts`)

**Goal:** Replace the entire batch pipeline â€” SQLiteâ†’Drizzle, old promptâ†’rubric-based, add validation/anomaly detection.

This is the largest phase. The current `scripts/batch.ts` (338 lines) uses better-sqlite3, temperature 0.3, and a naive scoring prompt. The rewrite touches every function.

### Files to modify:

#### 2.1 â€” Rewrite `scripts/batch.ts` (~480 lines)

**Structure (top to bottom):**

```
1. Imports (drizzle, schema, scoring.ts, dotenv)
2. Config (env vars â€” same keys, add RSS_FEEDS placeholder)
3. DB Setup (Drizzle pg pool â€” NOT db/index.ts, scripts run standalone)
4. NewsAPI fetcher (unchanged logic, minor cleanup)
5. callLLM() (temperature: 0, response_format: json_object)
6. extractJSON() (unchanged)
7. classifyArticles() (unchanged prompt â€” classification works fine)
8. FEW_SHOT_EXAMPLES constant (from US-1.0 Part 4.2)
9. SCORING_PROMPT template (from US-1.0 Part 4.3)
10. scoreTopic() â€” NEW rubric-based prompt
11. TopicScore interface â€” EXTENDED with levels, reasoning, raw response
12. processScoreResult() â€” NEW: validate, compute overall, detect anomalies
13. main() â€” rewritten with Drizzle queries
14. GDPR: 90-day audit log purge at end of batch
```

**Critical changes in detail:**

##### `callLLM()` changes:
```typescript
// OLD
temperature: 0.3
// No response_format

// NEW
temperature: 0,
response_format: { type: "json_object" },
```

##### `scoreTopic()` â€” complete replacement:
- Uses the rubric prompt from US-1.0 Part 4.3 (the ~500-token version with 4-level rubric + anti-bias instructions)
- Includes 4 few-shot calibration examples (one per level)
- Reasoning-first output order
- LLM no longer returns `score` or `urgency` â€” computed server-side
- INSUFFICIENT_DATA option for dimensions without evidence

##### New `TopicScore` interface:
```typescript
interface TopicScore {
  // From LLM:
  healthReasoning: string;
  healthLevel: string;
  healthScore: number;
  ecoReasoning: string;
  ecoLevel: string;
  ecoScore: number;
  econReasoning: string;
  econLevel: string;
  econScore: number;
  overallSummary: string;
  category: string;
  region: string;
  keywords: string[];
  // Computed server-side:
  overallScore: number;
  urgency: string;
  anomalyDetected: boolean;
  rawLlmResponse: string;
  // Validation metadata:
  clampedDimensions: string[];
}
```

##### `processScoreResult()` â€” NEW function:
```typescript
function processScoreResult(
  raw: LLMScoreResponse,
  rawJson: string,
  previousScores: { health: number; eco: number; econ: number } | null,
  topicName: string
): TopicScore
```
This function:
1. Validates each dimension via `validateScore()`
2. Logs clamped scores
3. Computes `overallScore` via `computeOverallScore()`
4. Derives `urgency` via `deriveUrgency()`
5. Detects anomalies per dimension via `detectAnomaly()`
6. Returns fully processed `TopicScore`

##### `main()` â€” Drizzle queries replace prepared statements:

```typescript
// Topic upsert (Drizzle)
await db.insert(topics).values({
  name: topicName,
  slug,
  category: scoreResult.category,
  region: scoreResult.region,
  currentScore: scoreResult.overallScore,
  healthScore: scoreResult.healthScore,
  ecoScore: scoreResult.ecoScore,
  econScore: scoreResult.econScore,
  scoreReasoning: scoreResult.overallSummary,
  urgency: scoreResult.urgency,
  impactSummary: scoreResult.overallSummary,
  imageUrl,
  articleCount: topicArticles.length,
}).onConflictDoUpdate({
  target: topics.slug,
  set: {
    previousScore: sql`${topics.currentScore}`,
    currentScore: scoreResult.overallScore,
    healthScore: scoreResult.healthScore,
    ecoScore: scoreResult.ecoScore,
    econScore: scoreResult.econScore,
    scoreReasoning: scoreResult.overallSummary,
    urgency: scoreResult.urgency,
    impactSummary: scoreResult.overallSummary,
    imageUrl: sql`COALESCE(${imageUrl}, ${topics.imageUrl})`,
    category: scoreResult.category,
    region: scoreResult.region,
    articleCount: sql`${topics.articleCount} + ${topicArticles.length}`,
    updatedAt: sql`CURRENT_TIMESTAMP`,
  },
});

// Score history insert (Drizzle)
await db.insert(scoreHistory).values({
  topicId: topicRow.id,
  score: scoreResult.overallScore,
  healthScore: scoreResult.healthScore,
  ecoScore: scoreResult.ecoScore,
  econScore: scoreResult.econScore,
  healthLevel: scoreResult.healthLevel,
  ecoLevel: scoreResult.ecoLevel,
  econLevel: scoreResult.econLevel,
  healthReasoning: scoreResult.healthReasoning,
  ecoReasoning: scoreResult.ecoReasoning,
  econReasoning: scoreResult.econReasoning,
  overallSummary: scoreResult.overallSummary,
  impactSummary: scoreResult.overallSummary,
  rawLlmResponse: scoreResult.rawLlmResponse,
  anomalyDetected: scoreResult.anomalyDetected,
});

// Articles with dedup (Drizzle)
for (const a of topicArticles) {
  await db.insert(articles).values({
    topicId: topicRow.id,
    title: a.title,
    url: a.url,
    source: a.source?.name,
    summary: a.description,
    imageUrl: a.urlToImage,
    publishedAt: a.publishedAt ? new Date(a.publishedAt) : null,
  }).onConflictDoNothing({ target: articles.url });
}

// Keywords with dedup (Drizzle)
for (const kw of scoreResult.keywords) {
  await db.insert(topicKeywords).values({
    topicId: topicRow.id,
    keyword: kw.toLowerCase(),
  }).onConflictDoNothing();
}
```

##### GDPR: 90-day audit log purge:
```typescript
// At end of main(), after all scoring
const purgeResult = await db.delete(auditLogs)
  .where(lt(auditLogs.timestamp, sql`NOW() - INTERVAL '90 days'`));
console.log(`Purged ${purgeResult.rowCount} audit logs older than 90 days`);
```

##### Batch-level validation:
```typescript
// After scoring all topics
const totalDimensions = clampedCounts.total;
const clampedDimensions = clampedCounts.clamped;
if (totalDimensions > 0 && clampedDimensions / totalDimensions > 0.3) {
  console.warn(
    `WARNING: ${((clampedDimensions/totalDimensions)*100).toFixed(1)}% of dimension scores were clamped. ` +
    `Possible model drift. Review LLM responses.`
  );
}
```

#### 2.2 â€” Script database connection pattern

Scripts run outside Next.js, so they can't use `src/db/index.ts` (which relies on Next.js env loading). Instead:

```typescript
import { drizzle } from "drizzle-orm/node-postgres";
import pg from "pg";
import * as schema from "../src/db/schema";
import "dotenv/config"; // Load .env for standalone script

const pool = new pg.Pool({ connectionString: process.env.DATABASE_URL });
const db = drizzle(pool, { schema });

// At end of main():
await pool.end();
```

This is the same pattern but with explicit dotenv loading (since Next.js auto-loads .env but standalone scripts don't).

### Checkpoint 2
```bash
# TypeScript compiles
npx tsc --noEmit scripts/batch.ts  # No errors (or use ts-jest)

# With local PostgreSQL running:
docker compose up -d postgres
npx drizzle-kit push
npx tsx scripts/batch.ts  # Runs full pipeline
# Verify: topics have sub-scores, levels, reasoning in DB
npx drizzle-kit studio  # Visual inspection
```

---

## Phase 3: Seed Script Rewrite (`scripts/seed.ts`)

**Goal:** Generate realistic v2 demo data with levels, reasoning, and severity distribution.

### File to modify:

#### 3.1 â€” Rewrite `scripts/seed.ts` (~280 lines)

**Key requirements from US-1.1 AC:**
- At least 2 topics per severity level (MINIMAL, MODERATE, SIGNIFICANT, SEVERE)
- At least 1 topic with one INSUFFICIENT_DATA dimension
- Realistic reasoning text (not lorem ipsum) â€” references seeded articles
- 7 days of score history with levels, reasoning, and varying severity
- Uses Drizzle ORM (not better-sqlite3)

**Seed data design (12 topics):**

| Topic | Overall | Health | Eco | Econ | Urgency | Notes |
|-------|---------|--------|-----|------|---------|-------|
| Amazon Deforestation | 82 | 28/MOD | 88/SEV | 62/SIG | breaking | Eco-driven SEVERE |
| Delhi Air Quality Crisis | 91 | 85/SEV | 35/MOD | 48/MOD | breaking | Health-driven SEVERE |
| Great Barrier Reef Bleaching | 69 | 28/MOD | 72/SIG | 58/SIG | critical | Eco-driven |
| California Wildfire Season | 62 | 55/SIG | 48/MOD | 45/MOD | critical | Health-driven |
| Plastic Ocean Pollution | 52 | 30/MOD | 58/SIG | 28/MOD | moderate | Eco-driven |
| Arctic Sea Ice Decline | 78 | 18/MIN | 82/SEV | 42/MOD | critical | Low health impact |
| European Heat Wave | 58 | 52/SIG | 38/MOD | 35/MOD | moderate | Health-driven |
| Congo Basin Mining Impact | 65 | 22/MIN | 72/SIG | 55/SIG | critical | Eco + Econ |
| Ganges River Pollution | 45 | 48/MOD | 38/MOD | 30/MOD | moderate | Balanced moderate |
| Renewable Energy Transition | 15 | 8/MIN | 12/MIN | 18/MIN | informational | All MINIMAL |
| Pacific Garbage Patch Growth | 48 | 26/MOD | 52/SIG | 28/MOD | moderate | Eco-driven moderate |
| Southeast Asian Flooding | 72 | 65/SIG | 42/MOD | 72/SIG | critical | Health + Econ driven |

**Special cases:**
- "Renewable Energy Transition" â€” all MINIMAL (positive news)
- Add one topic with INSUFFICIENT_DATA: e.g., "Deep Sea Mining Exploration" with `econLevel: "INSUFFICIENT_DATA"`, `econScore: -1`, `econReasoning: null` (articles don't discuss economic impact)

**Reasoning examples (realistic, article-referencing):**

```typescript
// Amazon Deforestation â€” Eco reasoning
"Satellite imagery confirms 12,000 kmÂ² of forest loss in 2025, the highest rate in 15 years. " +
"The Amazon stores approximately 150-200 billion tons of carbon, and continued deforestation " +
"threatens to push the ecosystem past a tipping point into savanna-like conditions."

// Delhi Air Quality â€” Health reasoning
"PM2.5 concentrations exceeded 500 Âµg/mÂ³ for three consecutive days, 33x the WHO guideline. " +
"Schools closed across the NCR region. Emergency hospital admissions for respiratory illness " +
"increased 40% compared to the same period last year."
```

**Score history generation:**
- 7 days of history per topic
- Scores vary within Â±15 of base, staying within the same level (mostly)
- 1-2 topics show a level transition over the 7 days (demonstrates escalation)
- Each history entry gets levels and abbreviated reasoning
- Use `scoreToLevel()` from `src/lib/scoring.ts` to ensure consistency

#### 3.2 â€” Seed script structure

```typescript
import "dotenv/config";
import { drizzle } from "drizzle-orm/node-postgres";
import pg from "pg";
import * as schema from "../src/db/schema";
import { scoreToLevel, computeOverallScore, deriveUrgency } from "../src/lib/scoring";

// 1. Connect
// 2. Clear existing data (in correct FK order)
// 3. Insert topics with sub-scores
// 4. Insert articles (3 per topic, realistic titles)
// 5. Insert score history (7 days per topic, with levels + reasoning)
// 6. Insert keywords
// 7. Summary + disconnect
```

### Checkpoint 3
```bash
# With local PostgreSQL running:
npx tsx scripts/seed.ts
# Output: "Seeded: 13 topics, 39 articles, 91 score history entries"

# Verify in Drizzle Studio:
npx drizzle-kit studio
# Check: topics have healthScore, ecoScore, econScore
# Check: score_history has levels, reasoning, overallSummary
# Check: at least 1 entry with INSUFFICIENT_DATA / -1

# Run dev server and visually verify:
npm run dev
# Dashboard shows topics with sub-scores
# Topic detail shows reasoning (once US-1.2 UI ships)
```

---

## Phase 4: Test Updates

**Goal:** Add unit tests for scoring functions and update existing batch/seed tests.

### Files to create/modify:

#### 4.1 â€” Create `tests/scoring.test.ts` (NEW â€” ~200 lines)

**Test groups:**

##### `validateScore()` (10 tests):
- Valid: MINIMAL score 15 â†’ no clamp
- Valid: SEVERE score 100 â†’ no clamp
- Clamp: MINIMAL score 30 â†’ clamped to 25
- Clamp: SEVERE score 50 â†’ clamped to 76
- Edge: score 0 with MINIMAL â†’ valid
- Edge: score 25 with MINIMAL â†’ valid (boundary)
- Edge: score 26 with MODERATE â†’ valid (boundary)
- INSUFFICIENT_DATA: returns level "INSUFFICIENT_DATA", score -1
- Unknown level: falls back to MODERATE, clamps to 26-50 range
- INSUFFICIENT_DATA score with valid level: corrected

##### `computeOverallScore()` (8 tests):
- All valid: weighted average (health=50, eco=60, econ=40 â†’ 51)
- One INSUFFICIENT_DATA: excluded, weights renormalized
- Two INSUFFICIENT_DATA: single dimension = full weight
- All INSUFFICIENT_DATA: fallback to 50
- All SEVERE (100, 100, 100): returns 100
- All MINIMAL (0, 0, 0): returns 0
- Eco-heavy: eco=100, health=0, econ=0 â†’ 40 (eco weight dominates)
- Rounding: verify Math.round behavior

##### `deriveUrgency()` (5 tests):
- 80 â†’ "breaking"
- 60 â†’ "critical"
- 30 â†’ "moderate"
- 29 â†’ "informational"
- 0 â†’ "informational"
- 100 â†’ "breaking"

##### `detectAnomaly()` (4 tests):
- 25pt jump: returns true
- 26pt jump: returns true
- 24pt jump: returns false
- 0â†’0: returns false
- Console.warn called when anomaly detected

##### `scoreToLevel()` (4 tests):
- 15 â†’ "MINIMAL"
- 40 â†’ "MODERATE"
- 65 â†’ "SIGNIFICANT"
- 90 â†’ "SEVERE"

#### 4.2 â€” Update `tests/batch.test.ts` (~50 lines changed)

- Add tests for `processScoreResult()` integration (validates + computes + detects anomaly)
- Update existing batch cycle test to verify new insert columns
- Test batch-level clamping warning (>30% clamped)
- Test GDPR audit log purge query

#### 4.3 â€” Update `tests/seed.test.ts` (~20 lines changed)

- Verify seed creates topics with sub-scores
- Verify score_history has levels and reasoning
- Verify at least one INSUFFICIENT_DATA entry exists
- Verify topic count matches expected (13)

### Checkpoint 4
```bash
npx jest  # All tests pass (existing 141 + new ~35 = ~176)
npx jest --coverage  # Coverage maintained or improved
```

---

## Summary: File Change Matrix

| File | Action | Lines (est.) | Phase |
|------|--------|-------------|-------|
| `src/lib/scoring.ts` | CREATE | ~120 | 1 |
| `scripts/batch.ts` | REWRITE | ~480 | 2 |
| `scripts/seed.ts` | REWRITE | ~280 | 3 |
| `tests/scoring.test.ts` | CREATE | ~200 | 4 |
| `tests/batch.test.ts` | MODIFY | ~50 Î” | 4 |
| `tests/seed.test.ts` | MODIFY | ~20 Î” | 4 |
| **Total** | | **~1,150** | |

**Files NOT changed** (already done in Phase 0):
- `src/db/schema.ts` â€” âœ… complete
- `src/db/index.ts` â€” âœ… complete
- `src/lib/types.ts` â€” âœ… complete
- `src/app/api/topics/route.ts` â€” âœ… already returns sub-scores
- `src/app/api/topics/[slug]/route.ts` â€” âœ… already returns levels + reasoning
- All component files â€” âœ… untouched (UI changes are US-1.2+)

---

## Risk Analysis

| Risk | Likelihood | Impact | Mitigation |
|------|-----------|--------|------------|
| Drizzle script import path issues | Medium | Low | Use explicit `../src/db/schema` import with dotenv |
| Few-shot examples bias scoring | Low | Medium | Examples chosen from diverse categories (urban, air, marine, nuclear) |
| `response_format: json_object` not supported by all OpenRouter models | Medium | Low | `extractJSON()` fallback already handles raw text responses |
| Test mock complexity for new Drizzle queries | Medium | Medium | Leverage existing mock-db.ts infrastructure |
| Seed data doesn't exercise all edge cases | Low | Low | Explicitly include INSUFFICIENT_DATA and level transitions |

---

## Implementation Notes

### Why `src/lib/scoring.ts` and not inline in batch.ts

Three reasons:
1. **Testability** â€” Pure functions with zero side effects. Import directly in tests without mocking anything.
2. **Reusability** â€” The seed script uses `scoreToLevel()` and `computeOverallScore()` to generate consistent demo data. Future UI components (US-2.2 methodology page) reference the same constants.
3. **Path alias** â€” `@/lib/scoring` works in all Next.js files. `scripts/batch.ts` can import via `../src/lib/scoring`.

### Why the prompt lives in batch.ts (not scoring.ts)

The scoring PROMPT is tightly coupled to the LLM call â€” it references `${topicName}` and `${articleSummaries}`. It's not a reusable utility. The scoring FUNCTIONS (validate, compute, derive) are reusable. Clean separation.

### Why scripts create their own DB pool

Next.js auto-loads `.env`. Scripts running via `npx tsx` don't. Using `dotenv/config` + a local Pool instance keeps scripts self-contained. Don't import from `@/db` â€” the path alias may not resolve outside Next.js context. Use relative imports: `../src/db/schema`.

### Commit strategy

Single commit after all 4 phases pass:
```
feat(scoring): implement US-1.1 multi-dimensional scoring architecture

- Add scoring utility library (validateScore, computeOverallScore, deriveUrgency, detectAnomaly)
- Rewrite batch pipeline: rubric-based 4-level prompt, temperature 0, server-side aggregation
- Rewrite seed script: realistic v2 data with levels, reasoning, INSUFFICIENT_DATA
- Add 35+ new tests for scoring functions and updated batch/seed tests
- GDPR: 90-day audit log auto-purge in batch pipeline
```

---

## Quick Reference: The 4-Level Rubric

| Level | Range | Criteria | Maps to |
|-------|-------|----------|---------|
| MINIMAL | 0-25 | Negligible risk, theoretical | informational |
| MODERATE | 26-50 | Localized, limited, reversible | moderate |
| SIGNIFICANT | 51-75 | Widespread, serious, hard to reverse | critical |
| SEVERE | 76-100 | Catastrophic, potentially irreversible | breaking |

**Weights:** Eco 40% Â· Health 35% Â· Econ 25%
**Temperature:** 0 (greedy decoding)
**Calibration:** 4 few-shot examples (one per level)
**Validation:** Server-side clamp to level range
**Anomaly:** >25pt jump per dimension

---

**Next step:** Review and approve this plan. Then execute with `/sc:implement` phase by phase.
